{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A custom Model\n",
    "This notebook shows how to implement and train a model other than the baseline used for this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import creating_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"F:\\Dropbox (Personal)\\BCII\\BCI Challenges\\2024 ALVI EMG Decoding\\dataset_v2_blocks\\dataset_v2_blocks\"\n",
    "data_paths = dict(datasets=[DATA_PATH],\n",
    "                    hand_type = ['left', 'right'], # [left, 'right']\n",
    "                    human_type = ['health', 'amputant'], # [amputant, 'health']\n",
    "                    test_dataset_list = ['fedya_tropin_standart_elbow_left'])\n",
    "data_config = creating_dataset.DataConfig(**data_paths)\n",
    "train_dataset, test_dataset = creating_dataset.get_datasets(data_config, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "We define a simple Multi Layer Perceptron, fully connected feedforward neural network with 2 hidden layers. The model is implemented using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try making a prediction using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, Y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}, Y shape: {Y.shape}\")\n",
    "\n",
    "n_inputs, n_outputs = X.shape[0], Y.shape[0]\n",
    "n_hidden = 64\n",
    "\n",
    "model = MLP(n_inputs, n_hidden, n_outputs)\n",
    "\n",
    "\n",
    "Y_hat = model(torch.tensor(X.T)).detach().numpy().T\n",
    "print(f\"Predictions shape: {Y_hat.shape}\")\n",
    "\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As upi cam see. The model's predictions are of the wrong shape: the outputs are not downsampled! Remember that inputs are sampled at 200Hz, but outputs are meant to be at 25Hz. We need to downsample the outputs to match the expected shape.\n",
    "\n",
    "You can choose your own downsampling method, but make sure that your predictions are aligned to the targets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def simple_downsample(x: np.ndarray) -> np.ndarray:\n",
    "    return x[:, ::data_config.down_sample_target]\n",
    "\n",
    "Y_hat = model(torch.tensor(X.T)).detach().numpy().T\n",
    "Y_hat = simple_downsample(Y_hat)\n",
    "\n",
    "\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, you can build the downsampling into your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_size, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x[::data_config.down_sample_target, :]\n",
    "    \n",
    "\n",
    "model = MLP(n_inputs, n_hidden, n_outputs)\n",
    "\n",
    "Y_hat = model(torch.tensor(X.T)).detach().numpy().T\n",
    "assert Y.shape == Y_hat.shape, \"Predictions have the wrong shape!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We define a very simple training procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MLP(n_inputs, n_hidden, n_outputs).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for X,Y in train_dataset:\n",
    "        X, Y = torch.tensor(X.T).to(device), torch.tensor(Y).to(device)\n",
    "        Y_hat = model(X).T\n",
    "\n",
    "        loss = criterion(Y_hat, Y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X, Y = test_dataset[0]\n",
    "\n",
    "Y_hat = model(torch.tensor(X.T).to(device)).detach().cpu().numpy().T\n",
    "\n",
    "f, axes = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(Y[i], label=\"True\", lw=2, color='k')\n",
    "    ax.plot(Y_hat[i], label=\"Predicted\", lw=1, color='r')\n",
    "\n",
    "    ax.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
